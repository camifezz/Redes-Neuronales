# Redes-Neuronales - TP1

## Tabla de Contenidos
- [Introducci√≥n](#Introducci√≥n)
- [Red recurrente](#Red-recurrente)
- [Modelo de Hopfield](#Modelo-de-Holpfield)
- [Trabajo Pr√°ctico](#Trabajo-Pr√°ctico)
    - [Punto a](#a--verifique-si-la-red-aprendi√≥-las-im√°genes-ense√±adas)
    - [Punto b](#b--eval√∫e-la-evoluci√≥n-de-la-red-al-presentarle-versiones-alteradas-de-las-im√°genesa-prendidas-agregado-de-ruido-elementos-borrados-o-agregados)
    - [Punto c]


## Introducci√≥n
### ¬øQu√© es una red neuronal biol√≥gica y como se imitan mediante algoritmos?
üß† `Red neuronal biol√≥gica`: funciona con neuronas, impulsos el√©ctricos y sinapsis. Cada neurona decide si transmite una se√±al en funci√≥n de la suma de sus entradas y la fuerza de las conexiones. El aprendizaje ocurre reforzando o debilitando esas conexiones.

üíª `Red neuronal artificial`: est√° compuesta por "nodos" o "neuronas artificiales" que realizan operaciones matem√°ticas simples.

Las redes neuronales artificiales imitan de manera muy simplificada la forma en que las redes biol√≥gicas procesan y aprenden informaci√≥n. No replican la complejidad del cerebro, pero toman la idea de "muchas unidades simples conectadas en red que, al trabajar juntas, generan comportamientos complejos".

Para que una red neuronal pueda funcionar correctamente necesita pasar por un proceso de entrenamiento, en el cual se ajustan los pesos de sus conexiones entre capas. Mediante la exposici√≥n a distintos conjuntos de datos, el sistema va perfeccionando su capacidad de aprendizaje, logrando que las neuronas artificiales reconozcan patrones y resuelvan problemas, ofreciendo respuestas que se asemejan a las de un ser humano.

## Red recurrente
Una red recurrente es aquella en donde las neuronas tienen conexiones que vuelven sobre s√≠ mismas o hacia otras neuronas en la misma capa, lo que permite que el sistema ‚Äúrecuerde‚Äù estados anteriores.

La red de Hopfield es una de ellas. En la pr√≥xima secci√≥n se hace una introducci√≥n al modelo

## Modelo de Hopfield
El modelo de Hopfield, propuesto por John Hopfield en 1982, es una de las primeras arquitecturas de redes neuronales artificiales que busc√≥ imitar el funcionamiento de la memoria en el cerebro

La idea principal es que la red pueda funcionar como una `memoria asociativa`:
- Durante el entrenamiento, se almacenan patrones en los pesos de la red.

- Cuando se le presenta un patr√≥n incompleto o ruidoso, la red evoluciona din√°micamente hasta estabilizarse en el patr√≥n correcto o en uno muy cercano.

#### Memoria asociativa
La memoria asociativa es la capacidad de un sistema de recordar informaci√≥n completa a partir de fragmentos o datos incompletos.
En el cerebro biol√≥gico ser√≠a, por ejemplo: ver solo una parte de una foto y aun as√≠ reconocer a la persona que aparece.

En una red de Hopfield, esta idea se implementa almacenando patrones en los pesos de las conexiones.

La memoria asociativa en Hopfield permite que la red act√∫e como un recordador de patrones, reconociendo informaci√≥n parcial y llev√°ndola al patr√≥n m√°s parecido que ya ten√≠a guardado.

## Trabajo Pr√°ctico
## Entrene una red de Hopfield ‚Äò82 con las im√°genes binarias disponibles en el campus.
### a- Verifique si la red aprendi√≥ las im√°genes ense√±adas.
Para probar esto, le presento a la red 3 im√°genes del mismo tama√±o y eval√∫o la convergencia de cada imagen.

![paloma](paloma-entrenamiento.png)
![quijote](quijote-entrenamiento.png)
![torero](torero-entrenamiento.png)

La imagen recuperada es la misma que el patr√≥n inicial. Por lo que podemos concluir que la red aprendi√≥ de los patrones ense√±ados.

### b- Eval√∫e la evoluci√≥n de la red al presentarle versiones alteradas de las im√°genesa prendidas: agregado de ruido, elementos borrados o agregados.

### Agregandole ruido a los patrones invirtiendo los bits
Para este punto eleg√≠ las im√°genes de tama√±o (50,50), les agregu√© diferentes grados de ruido y prob√© la red.
Eleg√≠ agregarle ruido invirtiendo bits de forma aleatoria.

Se puede ver que la red es bastante tolerante al ruido elegido, ya que logr√≥ converger a la imagen inicial en los 3 casos.

![panda](panda-con-ruido.png)
![v](v-con-ruido.png)
![perro](perro-con-ruido.png)



### Agregandole ruido a los patrones borrando diferentes porcentajes del patr√≥n

Se puede observar que borrando hasta un 70% del patr√≥n original la red converge de forma correcta.


#### 1- Borrando el 50% del patr√≥n original
![panda-borrado](panda-borrado-50.png)

#### 2- Borrando el 70% del patr√≥n original
![panda-borrado](panda-borrado-70.png)

#### 3- Borrando el 90% del patr√≥n original
![panda-borrado](panda-borrado-90.png)

### c- Eval√∫e la existencia de estados espurios en la red: patrones inversos y combinaciones de un n√∫mero impar de patrones.
#### Estados espurios

Una red de Hopfield es una red de memoria asociativa: entrena ciertos patrones ŒæŒº como m√≠nimos de energ√≠a.
Cuando a la red se le da una entrada ruidosa o incompleta, la din√°mica baja la ‚Äúenerg√≠a‚Äù y cae en el m√≠nimo m√°s cercano es decir, recupera el patr√≥n original.
Adem√°s de estos patrones entrenados, aparecen otros m√≠nimos estables que no son patrones originales, a esos m√≠nimos se los llama estados espurios.

#### Tipos de estados espurios
##### 1- Patrones inversos
Si ŒæŒº es un patr√≥n entrenado, su inverso -ŒæŒº tambi√©n puede ser un m√≠nimo estable.
Por ejemplo: Si la red memoriz√≥ un panda, la red puede converger tambi√©n en un "anti panda" todo invertido lo blaco/negro.
##### 2- Combinaciones de un n√∫mero impar de patrones
Un estado espurio tambi√©n puede ser una suma de k (n√∫mero impar) estados ense√±ados:

`s=sign(ŒæŒº1‚Äã+ŒæŒº2‚Äã+‚ãØ+ŒæŒº2k+1‚Äã)`

Es decir, si se entren√≥ la red con tres im√°genes distintas, la red puede generar una especie de mezcla h√≠brida de esas tres y tratar de recordarla como si fuera un patr√≥n real.

Visualmente, esas combinaciones suelen parecer ‚Äúfantasmas‚Äù de varios patrones mezclados.







