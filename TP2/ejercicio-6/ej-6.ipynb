{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Clasificación de MNIST con arquitecturas mínimas\n",
    "\n",
    "Buscamos la red convolucional y el perceptrón multicapa más pequeños que alcancen al menos 90% de exactitud en MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27bd04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los tensores MNIST\n",
    "Leemos los archivos `.pt` provistos (zip) y dejamos las imágenes normalizadas en `[0,1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([60000, 1, 28, 28]) Test: torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = Path('/home/camila/Documents/Redes Neuronales/Redes-Neuronales/TP2/ejercicio-6')\n",
    "\n",
    "def load_mnist_images(zip_path: Path) -> np.ndarray:\n",
    "    name = 'MNIST_train_data' if 'training' in zip_path.name else 'MNIST_test_data'\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        raw = z.read(f'{name}/data/0')\n",
    "    return np.frombuffer(raw, dtype=np.uint8).reshape(-1, 28, 28)\n",
    "\n",
    "def load_mnist_labels(zip_path: Path) -> np.ndarray:\n",
    "    name = 'MNIST_train_labels' if 'training' in zip_path.name else 'MNIST_test_labels'\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        raw = z.read(f'{name}/data/0')\n",
    "    return np.frombuffer(raw, dtype='<i8')\n",
    "\n",
    "train_images = load_mnist_images(DATA_DIR / 'MNIST_training_data.pt')\n",
    "test_images  = load_mnist_images(DATA_DIR / 'MNIST_test_data.pt')\n",
    "train_labels = load_mnist_labels(DATA_DIR / 'MNIST_training_labels.pt')\n",
    "test_labels  = load_mnist_labels(DATA_DIR / 'MNIST_test_labels.pt')\n",
    "\n",
    "train_images = torch.tensor(train_images, dtype=torch.float32).unsqueeze(1) / 255.0\n",
    "test_images  = torch.tensor(test_images, dtype=torch.float32).unsqueeze(1) / 255.0\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_labels  = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "print('Train:', train_images.shape, 'Test:', test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(train_images, train_labels), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(test_images, test_labels), batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, epochs: int, lr: float = 0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    history = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc = evaluate(model, train_loader)\n",
    "        test_acc = evaluate(model, test_loader)\n",
    "        history.append((train_acc, test_acc))\n",
    "        print(f\"Epoch {epoch:02d} - train acc {train_acc*100:.2f}% - eval acc {test_acc*100:.2f}%\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red convolucional mínima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros conv: 11738\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TinyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(8 * 12 * 12, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "conv_net = TinyConvNet().to(device)\n",
    "print('Parámetros conv:', count_params(conv_net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - train acc 93.88% - eval acc 93.96%\n",
      "Epoch 02 - train acc 96.30% - eval acc 96.52%\n",
      "Epoch 03 - train acc 97.26% - eval acc 97.29%\n",
      "Epoch 04 - train acc 97.75% - eval acc 97.67%\n",
      "Epoch 05 - train acc 98.06% - eval acc 97.83%\n",
      "Exactitud final (conv): 97.83%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_history = train_model(conv_net, train_loader, test_loader, epochs=5, lr=0.001)\n",
    "conv_test_acc = evaluate(conv_net, test_loader)\n",
    "print(f\"Exactitud final (conv): {conv_test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa mínimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros MLP: 50890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "mlp_net = TinyMLP().to(device)\n",
    "print('Parámetros MLP:', count_params(mlp_net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - train acc 93.62% - eval acc 93.54%\n",
      "Epoch 02 - train acc 95.58% - eval acc 95.11%\n",
      "Epoch 03 - train acc 96.59% - eval acc 96.04%\n",
      "Epoch 04 - train acc 97.23% - eval acc 96.61%\n",
      "Epoch 05 - train acc 97.50% - eval acc 96.74%\n",
      "Epoch 06 - train acc 97.96% - eval acc 97.00%\n",
      "Epoch 07 - train acc 98.30% - eval acc 97.18%\n",
      "Epoch 08 - train acc 98.45% - eval acc 97.35%\n",
      "Exactitud final (MLP): 97.35%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp_history = train_model(mlp_net, train_loader, test_loader, epochs=8, lr=0.0015)\n",
    "mlp_test_acc = evaluate(mlp_net, test_loader)\n",
    "print(f\"Exactitud final (MLP): {mlp_test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18788ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d26585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
